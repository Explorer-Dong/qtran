{"index": 42, "HTML": ["https://www.postgresql.org/docs/16/arrays.html"], "Title": ["8.15. Arrays"], "Feature": ["Arrays"], "Description": ["\n\n\n8.15.\u00a0Arrays #\n\n\n", "\n\n8.15.1. Declaration of Array Types\n8.15.2. Array Value Input\n8.15.3. Accessing Arrays\n8.15.4. Modifying Arrays\n8.15.5. Searching in Arrays\n8.15.6. Array Input and Output Syntax\n\n", "PostgreSQL allows columns of a table to be defined as variable-length multidimensional arrays. Arrays of any built-in or user-defined base type, enum type, composite type, range type, or domain can be created.", "\n\n\n\n8.15.1.\u00a0Declaration of Array Types #\n\n\n\nTo illustrate the use of array types, we create this table:\nCREATE TABLE sal_emp (\n    name            text,\n    pay_by_quarter  integer[],\n    schedule        text[][]\n);\n\nAs shown, an array data type is named by appending square brackets ([]) to the data type name of the array elements. The above command will create a table named sal_emp with a column of type text (name), a one-dimensional array of type integer (pay_by_quarter), which represents the employee's salary by quarter, and a two-dimensional array of text (schedule), which represents the employee's weekly schedule.\nThe syntax for CREATE TABLE allows the exact size of arrays to be specified, for example:\nCREATE TABLE tictactoe (\n    squares   integer[3][3]\n);\n\nHowever, the current implementation ignores any supplied array size limits, i.e., the behavior is the same as for arrays of unspecified length.\nThe current implementation does not enforce the declared number of dimensions either. Arrays of a particular element type are all considered to be of the same type, regardless of size or number of dimensions. So, declaring the array size or number of dimensions in CREATE TABLE is simply documentation; it does not affect run-time behavior.\nAn alternative syntax, which conforms to the SQL standard by using the keyword ARRAY, can be used for one-dimensional arrays. pay_by_quarter could have been defined as:\n    pay_by_quarter  integer ARRAY[4],\n\nOr, if no array size is to be specified:\n    pay_by_quarter  integer ARRAY,\n\nAs before, however, PostgreSQL does not enforce the size restriction in any case.\n", "\n\n\n\n8.15.2.\u00a0Array Value Input #\n\n\n\nTo write an array value as a literal constant, enclose the element values within curly braces and separate them by commas. (If you know C, this is not unlike the C syntax for initializing structures.) You can put double quotes around any element value, and must do so if it contains commas or curly braces. (More details appear below.) Thus, the general format of an array constant is the following:\n'{ val1 delim val2 delim ... }'\n\nwhere delim is the delimiter character for the type, as recorded in its pg_type entry. Among the standard data types provided in the PostgreSQL distribution, all use a comma (,), except for type box which uses a semicolon (;). Each val is either a constant of the array element type, or a subarray. An example of an array constant is:\n'{{1,2,3},{4,5,6},{7,8,9}}'\n\nThis constant is a two-dimensional, 3-by-3 array consisting of three subarrays of integers.\nTo set an element of an array constant to NULL, write NULL for the element value. (Any upper- or lower-case variant of NULL will do.) If you want an actual string value \u201cNULL\u201d, you must put double quotes around it.\n(These kinds of array constants are actually only a special case of the generic type constants discussed in Section\u00a04.1.2.7. The constant is initially treated as a string and passed to the array input conversion routine. An explicit type specification might be necessary.)\nNow we can show some INSERT statements:\nINSERT INTO sal_emp\n    VALUES ('Bill',\n    '{10000, 10000, 10000, 10000}',\n    '{{\"meeting\", \"lunch\"}, {\"training\", \"presentation\"}}');\n\nINSERT INTO sal_emp\n    VALUES ('Carol',\n    '{20000, 25000, 25000, 25000}',\n    '{{\"breakfast\", \"consulting\"}, {\"meeting\", \"lunch\"}}');\n\nThe result of the previous two inserts looks like this:\nSELECT * FROM sal_emp;\n name  |      pay_by_quarter       |                 schedule\n-------+---------------------------+-------------------------------------------\n Bill  | {10000,10000,10000,10000} | {{meeting,lunch},{training,presentation}}\n Carol | {20000,25000,25000,25000} | {{breakfast,consulting},{meeting,lunch}}\n(2 rows)\n\nMultidimensional arrays must have matching extents for each dimension. A mismatch causes an error, for example:\nINSERT INTO sal_emp\n    VALUES ('Bill',\n    '{10000, 10000, 10000, 10000}',\n    '{{\"meeting\", \"lunch\"}, {\"meeting\"}}');\nERROR:  multidimensional arrays must have array expressions with matching dimensions\n\nThe ARRAY constructor syntax can also be used:\nINSERT INTO sal_emp\n    VALUES ('Bill',\n    ARRAY[10000, 10000, 10000, 10000],\n    ARRAY[['meeting', 'lunch'], ['training', 'presentation']]);\n\nINSERT INTO sal_emp\n    VALUES ('Carol',\n    ARRAY[20000, 25000, 25000, 25000],\n    ARRAY[['breakfast', 'consulting'], ['meeting', 'lunch']]);\n\nNotice that the array elements are ordinary SQL constants or expressions; for instance, string literals are single quoted, instead of double quoted as they would be in an array literal. The ARRAY constructor syntax is discussed in more detail in Section\u00a04.2.12.\n", "\n\n\n\n8.15.3.\u00a0Accessing Arrays #\n\n\n\nNow, we can run some queries on the table. First, we show how to access a single element of an array. This query retrieves the names of the employees whose pay changed in the second quarter:\nSELECT name FROM sal_emp WHERE pay_by_quarter[1] <> pay_by_quarter[2];\n\n name\n-------\n Carol\n(1 row)\n\nThe array subscript numbers are written within square brackets. By default PostgreSQL uses a one-based numbering convention for arrays, that is, an array of n elements starts with array[1] and ends with array[n].\nThis query retrieves the third quarter pay of all employees:\nSELECT pay_by_quarter[3] FROM sal_emp;\n\n pay_by_quarter\n----------------\n          10000\n          25000\n(2 rows)\n\nWe can also access arbitrary rectangular slices of an array, or subarrays. An array slice is denoted by writing lower-bound:upper-bound for one or more array dimensions. For example, this query retrieves the first item on Bill's schedule for the first two days of the week:\nSELECT schedule[1:2][1:1] FROM sal_emp WHERE name = 'Bill';\n\n        schedule\n------------------------\n {{meeting},{training}}\n(1 row)\n\nIf any dimension is written as a slice, i.e., contains a colon, then all dimensions are treated as slices. Any dimension that has only a single number (no colon) is treated as being from 1 to the number specified. For example, [2] is treated as [1:2], as in this example:\nSELECT schedule[1:2][2] FROM sal_emp WHERE name = 'Bill';\n\n                 schedule\n-------------------------------------------\n {{meeting,lunch},{training,presentation}}\n(1 row)\n\nTo avoid confusion with the non-slice case, it's best to use slice syntax for all dimensions, e.g., [1:2][1:1], not [2][1:1].\nIt is possible to omit the lower-bound and/or upper-bound of a slice specifier; the missing bound is replaced by the lower or upper limit of the array's subscripts. For example:\nSELECT schedule[:2][2:] FROM sal_emp WHERE name = 'Bill';\n\n        schedule\n------------------------\n {{lunch},{presentation}}\n(1 row)\n\nSELECT schedule[:][1:1] FROM sal_emp WHERE name = 'Bill';\n\n        schedule\n------------------------\n {{meeting},{training}}\n(1 row)\n\nAn array subscript expression will return null if either the array itself or any of the subscript expressions are null. Also, null is returned if a subscript is outside the array bounds (this case does not raise an error). For example, if schedule currently has the dimensions [1:3][1:2] then referencing schedule[3][3] yields NULL. Similarly, an array reference with the wrong number of subscripts yields a null rather than an error.\nAn array slice expression likewise yields null if the array itself or any of the subscript expressions are null. However, in other cases such as selecting an array slice that is completely outside the current array bounds, a slice expression yields an empty (zero-dimensional) array instead of null. (This does not match non-slice behavior and is done for historical reasons.) If the requested slice partially overlaps the array bounds, then it is silently reduced to just the overlapping region instead of returning null.\nThe current dimensions of any array value can be retrieved with the array_dims function:\nSELECT array_dims(schedule) FROM sal_emp WHERE name = 'Carol';\n\n array_dims\n------------\n [1:2][1:2]\n(1 row)\n\narray_dims produces a text result, which is convenient for people to read but perhaps inconvenient for programs. Dimensions can also be retrieved with array_upper and array_lower, which return the upper and lower bound of a specified array dimension, respectively:\nSELECT array_upper(schedule, 1) FROM sal_emp WHERE name = 'Carol';\n\n array_upper\n-------------\n           2\n(1 row)\n\narray_length will return the length of a specified array dimension:\nSELECT array_length(schedule, 1) FROM sal_emp WHERE name = 'Carol';\n\n array_length\n--------------\n            2\n(1 row)\n\ncardinality returns the total number of elements in an array across all dimensions. It is effectively the number of rows a call to unnest would yield:\nSELECT cardinality(schedule) FROM sal_emp WHERE name = 'Carol';\n\n cardinality\n-------------\n           4\n(1 row)\n\n", "\n\n\n\n8.15.4.\u00a0Modifying Arrays #\n\n\n\nAn array value can be replaced completely:\nUPDATE sal_emp SET pay_by_quarter = '{25000,25000,27000,27000}'\n    WHERE name = 'Carol';\n\nor using the ARRAY expression syntax:\nUPDATE sal_emp SET pay_by_quarter = ARRAY[25000,25000,27000,27000]\n    WHERE name = 'Carol';\n\nAn array can also be updated at a single element:\nUPDATE sal_emp SET pay_by_quarter[4] = 15000\n    WHERE name = 'Bill';\n\nor updated in a slice:\nUPDATE sal_emp SET pay_by_quarter[1:2] = '{27000,27000}'\n    WHERE name = 'Carol';\n\nThe slice syntaxes with omitted lower-bound and/or upper-bound can be used too, but only when updating an array value that is not NULL or zero-dimensional (otherwise, there is no existing subscript limit to substitute).\nA stored array value can be enlarged by assigning to elements not already present. Any positions between those previously present and the newly assigned elements will be filled with nulls. For example, if array myarray currently has 4 elements, it will have six elements after an update that assigns to myarray[6]; myarray[5] will contain null. Currently, enlargement in this fashion is only allowed for one-dimensional arrays, not multidimensional arrays.\nSubscripted assignment allows creation of arrays that do not use one-based subscripts. For example one might assign to myarray[-2:7] to create an array with subscript values from -2 to 7.\nNew array values can also be constructed using the concatenation operator, ||:\nSELECT ARRAY[1,2] || ARRAY[3,4];\n ?column?\n-----------\n {1,2,3,4}\n(1 row)\n\nSELECT ARRAY[5,6] || ARRAY[[1,2],[3,4]];\n      ?column?\n---------------------\n {{5,6},{1,2},{3,4}}\n(1 row)\n\nThe concatenation operator allows a single element to be pushed onto the beginning or end of a one-dimensional array. It also accepts two N-dimensional arrays, or an N-dimensional and an N+1-dimensional array.\nWhen a single element is pushed onto either the beginning or end of a one-dimensional array, the result is an array with the same lower bound subscript as the array operand. For example:\nSELECT array_dims(1 || '[0:1]={2,3}'::int[]);\n array_dims\n------------\n [0:2]\n(1 row)\n\nSELECT array_dims(ARRAY[1,2] || 3);\n array_dims\n------------\n [1:3]\n(1 row)\n\nWhen two arrays with an equal number of dimensions are concatenated, the result retains the lower bound subscript of the left-hand operand's outer dimension. The result is an array comprising every element of the left-hand operand followed by every element of the right-hand operand. For example:\nSELECT array_dims(ARRAY[1,2] || ARRAY[3,4,5]);\n array_dims\n------------\n [1:5]\n(1 row)\n\nSELECT array_dims(ARRAY[[1,2],[3,4]] || ARRAY[[5,6],[7,8],[9,0]]);\n array_dims\n------------\n [1:5][1:2]\n(1 row)\n\nWhen an N-dimensional array is pushed onto the beginning or end of an N+1-dimensional array, the result is analogous to the element-array case above. Each N-dimensional sub-array is essentially an element of the N+1-dimensional array's outer dimension. For example:\nSELECT array_dims(ARRAY[1,2] || ARRAY[[3,4],[5,6]]);\n array_dims\n------------\n [1:3][1:2]\n(1 row)\n\nAn array can also be constructed by using the functions array_prepend, array_append, or array_cat. The first two only support one-dimensional arrays, but array_cat supports multidimensional arrays. Some examples:\nSELECT array_prepend(1, ARRAY[2,3]);\n array_prepend\n---------------\n {1,2,3}\n(1 row)\n\nSELECT array_append(ARRAY[1,2], 3);\n array_append\n--------------\n {1,2,3}\n(1 row)\n\nSELECT array_cat(ARRAY[1,2], ARRAY[3,4]);\n array_cat\n-----------\n {1,2,3,4}\n(1 row)\n\nSELECT array_cat(ARRAY[[1,2],[3,4]], ARRAY[5,6]);\n      array_cat\n---------------------\n {{1,2},{3,4},{5,6}}\n(1 row)\n\nSELECT array_cat(ARRAY[5,6], ARRAY[[1,2],[3,4]]);\n      array_cat\n---------------------\n {{5,6},{1,2},{3,4}}\n\nIn simple cases, the concatenation operator discussed above is preferred over direct use of these functions. However, because the concatenation operator is overloaded to serve all three cases, there are situations where use of one of the functions is helpful to avoid ambiguity. For example consider:\nSELECT ARRAY[1, 2] || '{3, 4}';  -- the untyped literal is taken as an array\n ?column?\n-----------\n {1,2,3,4}\n\nSELECT ARRAY[1, 2] || '7';                 -- so is this one\nERROR:  malformed array literal: \"7\"\n\nSELECT ARRAY[1, 2] || NULL;                -- so is an undecorated NULL\n ?column?\n----------\n {1,2}\n(1 row)\n\nSELECT array_append(ARRAY[1, 2], NULL);    -- this might have been meant\n array_append\n--------------\n {1,2,NULL}\n\nIn the examples above, the parser sees an integer array on one side of the concatenation operator, and a constant of undetermined type on the other. The heuristic it uses to resolve the constant's type is to assume it's of the same type as the operator's other input \u2014 in this case, integer array. So the concatenation operator is presumed to represent array_cat, not array_append. When that's the wrong choice, it could be fixed by casting the constant to the array's element type; but explicit use of array_append might be a preferable solution.\n", "\n\n\n\n8.15.5.\u00a0Searching in Arrays #\n\n\n\nTo search for a value in an array, each value must be checked. This can be done manually, if you know the size of the array. For example:\nSELECT * FROM sal_emp WHERE pay_by_quarter[1] = 10000 OR\n                            pay_by_quarter[2] = 10000 OR\n                            pay_by_quarter[3] = 10000 OR\n                            pay_by_quarter[4] = 10000;\n\nHowever, this quickly becomes tedious for large arrays, and is not helpful if the size of the array is unknown. An alternative method is described in Section\u00a09.24. The above query could be replaced by:\nSELECT * FROM sal_emp WHERE 10000 = ANY (pay_by_quarter);\n\nIn addition, you can find rows where the array has all values equal to 10000 with:\nSELECT * FROM sal_emp WHERE 10000 = ALL (pay_by_quarter);\n\nAlternatively, the generate_subscripts function can be used. For example:\nSELECT * FROM\n   (SELECT pay_by_quarter,\n           generate_subscripts(pay_by_quarter, 1) AS s\n      FROM sal_emp) AS foo\n WHERE pay_by_quarter[s] = 10000;\n\nThis function is described in Table\u00a09.66.\nYou can also search an array using the && operator, which checks whether the left operand overlaps with the right operand. For instance:\nSELECT * FROM sal_emp WHERE pay_by_quarter && ARRAY[10000];\n\nThis and other array operators are further described in Section\u00a09.19. It can be accelerated by an appropriate index, as described in Section\u00a011.2.\nYou can also search for specific values in an array using the array_position and array_positions functions. The former returns the subscript of the first occurrence of a value in an array; the latter returns an array with the subscripts of all occurrences of the value in the array. For example:\nSELECT array_position(ARRAY['sun','mon','tue','wed','thu','fri','sat'], 'mon');\n array_position\n----------------\n              2\n(1 row)\n\nSELECT array_positions(ARRAY[1, 4, 3, 1, 3, 4, 2, 1], 1);\n array_positions\n-----------------\n {1,4,8}\n(1 row)\n\n\nTip\nArrays are not sets; searching for specific array elements can be a sign of database misdesign. Consider using a separate table with a row for each item that would be an array element. This will be easier to search, and is likely to scale better for a large number of elements.\n\n", "\n\n\n\n8.15.6.\u00a0Array Input and Output Syntax #\n\n\n\nThe external text representation of an array value consists of items that are interpreted according to the I/O conversion rules for the array's element type, plus decoration that indicates the array structure. The decoration consists of curly braces ({ and }) around the array value plus delimiter characters between adjacent items. The delimiter character is usually a comma (,) but can be something else: it is determined by the typdelim setting for the array's element type. Among the standard data types provided in the PostgreSQL distribution, all use a comma, except for type box, which uses a semicolon (;). In a multidimensional array, each dimension (row, plane, cube, etc.) gets its own level of curly braces, and delimiters must be written between adjacent curly-braced entities of the same level.\nThe array output routine will put double quotes around element values if they are empty strings, contain curly braces, delimiter characters, double quotes, backslashes, or white space, or match the word NULL. Double quotes and backslashes embedded in element values will be backslash-escaped. For numeric data types it is safe to assume that double quotes will never appear, but for textual data types one should be prepared to cope with either the presence or absence of quotes.\nBy default, the lower bound index value of an array's dimensions is set to one. To represent arrays with other lower bounds, the array subscript ranges can be specified explicitly before writing the array contents. This decoration consists of square brackets ([]) around each array dimension's lower and upper bounds, with a colon (:) delimiter character in between. The array dimension decoration is followed by an equal sign (=). For example:\nSELECT f1[1][-2][3] AS e1, f1[1][-1][5] AS e2\n FROM (SELECT '[1:1][-2:-1][3:5]={{{1,2,3},{4,5,6}}}'::int[] AS f1) AS ss;\n\n e1 | e2\n----+----\n  1 |  6\n(1 row)\n\nThe array output routine will include explicit dimensions in its result only when there are one or more lower bounds different from one.\nIf the value written for an element is NULL (in any case variant), the element is taken to be NULL. The presence of any quotes or backslashes disables this and allows the literal string value \u201cNULL\u201d to be entered. Also, for backward compatibility with pre-8.2 versions of PostgreSQL, the array_nulls configuration parameter can be turned off to suppress recognition of NULL as a NULL.\nAs shown previously, when writing an array value you can use double quotes around any individual array element. You must do so if the element value would otherwise confuse the array-value parser. For example, elements containing curly braces, commas (or the data type's delimiter character), double quotes, backslashes, or leading or trailing whitespace must be double-quoted. Empty strings and strings matching the word NULL must be quoted, too. To put a double quote or backslash in a quoted array element value, precede it with a backslash. Alternatively, you can avoid quotes and use backslash-escaping to protect all data characters that would otherwise be taken as array syntax.\nYou can add whitespace before a left brace or after a right brace. You can also add whitespace before or after any individual item string. In all of these cases the whitespace will be ignored. However, whitespace within double-quoted elements, or surrounded on both sides by non-whitespace characters of an element, is not ignored.\n\nTip\nThe ARRAY constructor syntax (see Section\u00a04.2.12) is often easier to work with than the array-literal syntax when writing array values in SQL commands. In ARRAY, individual element values are written the same way they would be written when not members of an array.\n\n"], "Examples": [], "Category": ["Nested or Composite Data Types"]}
{"index": 43, "HTML": ["https://www.postgresql.org/docs/16/rowtypes.html"], "Title": ["8.16. Composite Types"], "Feature": ["Composite Types"], "Description": ["\n\n\n8.16.\u00a0Composite Types #\n\n\n", "\n\n8.16.1. Declaration of Composite Types\n8.16.2. Constructing Composite Values\n8.16.3. Accessing Composite Types\n8.16.4. Modifying Composite Types\n8.16.5. Using Composite Types in Queries\n8.16.6. Composite Type Input and Output Syntax\n\n", "A composite type represents the structure of a row or record; it is essentially just a list of field names and their data types. PostgreSQL allows composite types to be used in many of the same ways that simple types can be used. For example, a column of a table can be declared to be of a composite type.", "\n\n\n\n8.16.1.\u00a0Declaration of Composite Types #\n\n\n\nHere are two simple examples of defining composite types:\nCREATE TYPE complex AS (\n    r       double precision,\n    i       double precision\n);\n\nCREATE TYPE inventory_item AS (\n    name            text,\n    supplier_id     integer,\n    price           numeric\n);\n\nThe syntax is comparable to CREATE TABLE, except that only field names and types can be specified; no constraints (such as NOT NULL) can presently be included. Note that the AS keyword is essential; without it, the system will think a different kind of CREATE TYPE command is meant, and you will get odd syntax errors.\nHaving defined the types, we can use them to create tables:\nCREATE TABLE on_hand (\n    item      inventory_item,\n    count     integer\n);\n\nINSERT INTO on_hand VALUES (ROW('fuzzy dice', 42, 1.99), 1000);\n\nor functions:\nCREATE FUNCTION price_extension(inventory_item, integer) RETURNS numeric\nAS 'SELECT $1.price * $2' LANGUAGE SQL;\n\nSELECT price_extension(item, 10) FROM on_hand;\n\nWhenever you create a table, a composite type is also automatically created, with the same name as the table, to represent the table's row type. For example, had we said:\nCREATE TABLE inventory_item (\n    name            text,\n    supplier_id     integer REFERENCES suppliers,\n    price           numeric CHECK (price > 0)\n);\n\nthen the same inventory_item composite type shown above would come into being as a byproduct, and could be used just as above. Note however an important restriction of the current implementation: since no constraints are associated with a composite type, the constraints shown in the table definition do not apply to values of the composite type outside the table. (To work around this, create a domain over the composite type, and apply the desired constraints as CHECK constraints of the domain.)\n", "\n\n\n\n8.16.2.\u00a0Constructing Composite Values #\n\n\n\nTo write a composite value as a literal constant, enclose the field values within parentheses and separate them by commas. You can put double quotes around any field value, and must do so if it contains commas or parentheses. (More details appear below.) Thus, the general format of a composite constant is the following:\n'( val1 , val2 , ... )'\n\nAn example is:\n'(\"fuzzy dice\",42,1.99)'\n\nwhich would be a valid value of the inventory_item type defined above. To make a field be NULL, write no characters at all in its position in the list. For example, this constant specifies a NULL third field:\n'(\"fuzzy dice\",42,)'\n\nIf you want an empty string rather than NULL, write double quotes:\n'(\"\",42,)'\n\nHere the first field is a non-NULL empty string, the third is NULL.\n(These constants are actually only a special case of the generic type constants discussed in Section\u00a04.1.2.7. The constant is initially treated as a string and passed to the composite-type input conversion routine. An explicit type specification might be necessary to tell which type to convert the constant to.)\nThe ROW expression syntax can also be used to construct composite values. In most cases this is considerably simpler to use than the string-literal syntax since you don't have to worry about multiple layers of quoting. We already used this method above:\nROW('fuzzy dice', 42, 1.99)\nROW('', 42, NULL)\n\nThe ROW keyword is actually optional as long as you have more than one field in the expression, so these can be simplified to:\n('fuzzy dice', 42, 1.99)\n('', 42, NULL)\n\nThe ROW expression syntax is discussed in more detail in Section\u00a04.2.13.\n", "\n\n\n\n8.16.3.\u00a0Accessing Composite Types #\n\n\n\nTo access a field of a composite column, one writes a dot and the field name, much like selecting a field from a table name. In fact, it's so much like selecting from a table name that you often have to use parentheses to keep from confusing the parser. For example, you might try to select some subfields from our on_hand example table with something like:\nSELECT item.name FROM on_hand WHERE item.price > 9.99;\n\nThis will not work since the name item is taken to be a table name, not a column name of on_hand, per SQL syntax rules. You must write it like this:\nSELECT (item).name FROM on_hand WHERE (item).price > 9.99;\n\nor if you need to use the table name as well (for instance in a multitable query), like this:\nSELECT (on_hand.item).name FROM on_hand WHERE (on_hand.item).price > 9.99;\n\nNow the parenthesized object is correctly interpreted as a reference to the item column, and then the subfield can be selected from it.\nSimilar syntactic issues apply whenever you select a field from a composite value. For instance, to select just one field from the result of a function that returns a composite value, you'd need to write something like:\nSELECT (my_func(...)).field FROM ...\n\nWithout the extra parentheses, this will generate a syntax error.\nThe special field name * means \u201call fields\u201d, as further explained in Section\u00a08.16.5.\n", "\n\n\n\n8.16.4.\u00a0Modifying Composite Types #\n\n\n\nHere are some examples of the proper syntax for inserting and updating composite columns. First, inserting or updating a whole column:\nINSERT INTO mytab (complex_col) VALUES((1.1,2.2));\n\nUPDATE mytab SET complex_col = ROW(1.1,2.2) WHERE ...;\n\nThe first example omits ROW, the second uses it; we could have done it either way.\nWe can update an individual subfield of a composite column:\nUPDATE mytab SET complex_col.r = (complex_col).r + 1 WHERE ...;\n\nNotice here that we don't need to (and indeed cannot) put parentheses around the column name appearing just after SET, but we do need parentheses when referencing the same column in the expression to the right of the equal sign.\nAnd we can specify subfields as targets for INSERT, too:\nINSERT INTO mytab (complex_col.r, complex_col.i) VALUES(1.1, 2.2);\n\nHad we not supplied values for all the subfields of the column, the remaining subfields would have been filled with null values.\n", "\n\n\n\n8.16.5.\u00a0Using Composite Types in Queries #\n\n\n\nThere are various special syntax rules and behaviors associated with composite types in queries. These rules provide useful shortcuts, but can be confusing if you don't know the logic behind them.\nIn PostgreSQL, a reference to a table name (or alias) in a query is effectively a reference to the composite value of the table's current row. For example, if we had a table inventory_item as shown above, we could write:\nSELECT c FROM inventory_item c;\n\nThis query produces a single composite-valued column, so we might get output like:\n           c\n------------------------\n (\"fuzzy dice\",42,1.99)\n(1 row)\n\nNote however that simple names are matched to column names before table names, so this example works only because there is no column named c in the query's tables.\nThe ordinary qualified-column-name syntax table_name.column_name can be understood as applying field selection to the composite value of the table's current row. (For efficiency reasons, it's not actually implemented that way.)\nWhen we write\nSELECT c.* FROM inventory_item c;\n\nthen, according to the SQL standard, we should get the contents of the table expanded into separate columns:\n    name    | supplier_id | price\n------------+-------------+-------\n fuzzy dice |          42 |  1.99\n(1 row)\n\nas if the query were\nSELECT c.name, c.supplier_id, c.price FROM inventory_item c;\n\nPostgreSQL will apply this expansion behavior to any composite-valued expression, although as shown above, you need to write parentheses around the value that .* is applied to whenever it's not a simple table name. For example, if myfunc() is a function returning a composite type with columns a, b, and c, then these two queries have the same result:\nSELECT (myfunc(x)).* FROM some_table;\nSELECT (myfunc(x)).a, (myfunc(x)).b, (myfunc(x)).c FROM some_table;\n\n\nTip\nPostgreSQL handles column expansion by actually transforming the first form into the second. So, in this example, myfunc() would get invoked three times per row with either syntax. If it's an expensive function you may wish to avoid that, which you can do with a query like:\nSELECT m.* FROM some_table, LATERAL myfunc(x) AS m;\n\nPlacing the function in a LATERAL FROM item keeps it from being invoked more than once per row. m.* is still expanded into m.a, m.b, m.c, but now those variables are just references to the output of the FROM item. (The LATERAL keyword is optional here, but we show it to clarify that the function is getting x from some_table.)\n\nThe composite_value.* syntax results in column expansion of this kind when it appears at the top level of a SELECT output list, a RETURNING list in INSERT/UPDATE/DELETE, a VALUES clause, or a row constructor. In all other contexts (including when nested inside one of those constructs), attaching .* to a composite value does not change the value, since it means \u201call columns\u201d and so the same composite value is produced again. For example, if somefunc() accepts a composite-valued argument, these queries are the same:\nSELECT somefunc(c.*) FROM inventory_item c;\nSELECT somefunc(c) FROM inventory_item c;\n\nIn both cases, the current row of inventory_item is passed to the function as a single composite-valued argument. Even though .* does nothing in such cases, using it is good style, since it makes clear that a composite value is intended. In particular, the parser will consider c in c.* to refer to a table name or alias, not to a column name, so that there is no ambiguity; whereas without .*, it is not clear whether c means a table name or a column name, and in fact the column-name interpretation will be preferred if there is a column named c.\nAnother example demonstrating these concepts is that all these queries mean the same thing:\nSELECT * FROM inventory_item c ORDER BY c;\nSELECT * FROM inventory_item c ORDER BY c.*;\nSELECT * FROM inventory_item c ORDER BY ROW(c.*);\n\nAll of these ORDER BY clauses specify the row's composite value, resulting in sorting the rows according to the rules described in Section\u00a09.24.6. However, if inventory_item contained a column named c, the first case would be different from the others, as it would mean to sort by that column only. Given the column names previously shown, these queries are also equivalent to those above:\nSELECT * FROM inventory_item c ORDER BY ROW(c.name, c.supplier_id, c.price);\nSELECT * FROM inventory_item c ORDER BY (c.name, c.supplier_id, c.price);\n\n(The last case uses a row constructor with the key word ROW omitted.)\nAnother special syntactical behavior associated with composite values is that we can use functional notation for extracting a field of a composite value. The simple way to explain this is that the notations field(table) and table.field are interchangeable. For example, these queries are equivalent:\nSELECT c.name FROM inventory_item c WHERE c.price > 1000;\nSELECT name(c) FROM inventory_item c WHERE price(c) > 1000;\n\nMoreover, if we have a function that accepts a single argument of a composite type, we can call it with either notation. These queries are all equivalent:\nSELECT somefunc(c) FROM inventory_item c;\nSELECT somefunc(c.*) FROM inventory_item c;\nSELECT c.somefunc FROM inventory_item c;\n\nThis equivalence between functional notation and field notation makes it possible to use functions on composite types to implement \u201ccomputed fields\u201d.   An application using the last query above wouldn't need to be directly aware that somefunc isn't a real column of the table.\n\nTip\nBecause of this behavior, it's unwise to give a function that takes a single composite-type argument the same name as any of the fields of that composite type. If there is ambiguity, the field-name interpretation will be chosen if field-name syntax is used, while the function will be chosen if function-call syntax is used. However, PostgreSQL versions before 11 always chose the field-name interpretation, unless the syntax of the call required it to be a function call. One way to force the function interpretation in older versions is to schema-qualify the function name, that is, write schema.func(compositevalue).\n\n", "\n\n\n\n8.16.6.\u00a0Composite Type Input and Output Syntax #\n\n\n\nThe external text representation of a composite value consists of items that are interpreted according to the I/O conversion rules for the individual field types, plus decoration that indicates the composite structure. The decoration consists of parentheses (( and )) around the whole value, plus commas (,) between adjacent items. Whitespace outside the parentheses is ignored, but within the parentheses it is considered part of the field value, and might or might not be significant depending on the input conversion rules for the field data type. For example, in:\n'(  42)'\n\nthe whitespace will be ignored if the field type is integer, but not if it is text.\nAs shown previously, when writing a composite value you can write double quotes around any individual field value. You must do so if the field value would otherwise confuse the composite-value parser. In particular, fields containing parentheses, commas, double quotes, or backslashes must be double-quoted. To put a double quote or backslash in a quoted composite field value, precede it with a backslash. (Also, a pair of double quotes within a double-quoted field value is taken to represent a double quote character, analogously to the rules for single quotes in SQL literal strings.) Alternatively, you can avoid quoting and use backslash-escaping to protect all data characters that would otherwise be taken as composite syntax.\nA completely empty field value (no characters at all between the commas or parentheses) represents a NULL. To write a value that is an empty string rather than NULL, write \"\".\nThe composite output routine will put double quotes around field values if they are empty strings or contain parentheses, commas, double quotes, backslashes, or white space. (Doing so for white space is not essential, but aids legibility.) Double quotes and backslashes embedded in field values will be doubled.\n\nNote\nRemember that what you write in an SQL command will first be interpreted as a string literal, and then as a composite. This doubles the number of backslashes you need (assuming escape string syntax is used). For example, to insert a text field containing a double quote and a backslash in a composite value, you'd need to write:\nINSERT ... VALUES ('(\"\\\"\\\\\")');\n\nThe string-literal processor removes one level of backslashes, so that what arrives at the composite-value parser looks like (\"\\\"\\\\\"). In turn, the string fed to the text data type's input routine becomes \"\\. (If we were working with a data type whose input routine also treated backslashes specially, bytea for example, we might need as many as eight backslashes in the command to get one backslash into the stored composite field.) Dollar quoting (see Section\u00a04.1.2.4) can be used to avoid the need to double backslashes.\n\n\nTip\nThe ROW constructor syntax is usually easier to work with than the composite-literal syntax when writing composite values in SQL commands. In ROW, individual field values are written the same way they would be written when not members of a composite.\n\n"], "Examples": [], "Category": ["Nested or Composite Data Types"]}
{"index": 44, "HTML": ["https://www.postgresql.org/docs/16/rangetypes.html"], "Title": ["8.17. Range Types"], "Feature": ["Range Types"], "Description": ["\n\n\n8.17.\u00a0Range Types #\n\n\n", "\n\n8.17.1. Built-in Range and Multirange Types\n8.17.2. Examples\n8.17.3. Inclusive and Exclusive Bounds\n8.17.4. Infinite (Unbounded) Ranges\n8.17.5. Range Input/Output\n8.17.6. Constructing Ranges and Multiranges\n8.17.7. Discrete Range Types\n8.17.8. Defining New Range Types\n8.17.9. Indexing\n8.17.10. Constraints on Ranges\n\n", "Range types are data types representing a range of values of some element type (called the range's subtype). For instance, ranges of timestamp might be used to represent the ranges of time that a meeting room is reserved. In this case the data type is tsrange (short for \u201ctimestamp range\u201d), and timestamp is the subtype. The subtype must have a total order so that it is well-defined whether element values are within, before, or after a range of values.", "Range types are useful because they represent many element values in a single range value, and because concepts such as overlapping ranges can be expressed clearly. The use of time and date ranges for scheduling purposes is the clearest example; but price ranges, measurement ranges from an instrument, and so forth can also be useful.", "Every range type has a corresponding multirange type. A multirange is an ordered list of non-contiguous, non-empty, non-null ranges. Most range operators also work on multiranges, and they have a few functions of their own.", "\n\n\n\n8.17.1.\u00a0Built-in Range and Multirange Types #\n\n\n\nPostgreSQL comes with the following built-in range types:\n\n\n\nint4range \u2014 Range of integer, int4multirange \u2014 corresponding Multirange\n\n\nint8range \u2014 Range of bigint, int8multirange \u2014 corresponding Multirange\n\n\nnumrange \u2014 Range of numeric, nummultirange \u2014 corresponding Multirange\n\n\ntsrange \u2014 Range of timestamp without time zone, tsmultirange \u2014 corresponding Multirange\n\n\ntstzrange \u2014 Range of timestamp with time zone, tstzmultirange \u2014 corresponding Multirange\n\n\ndaterange \u2014 Range of date, datemultirange \u2014 corresponding Multirange\n\n\n\nIn addition, you can define your own range types; see CREATE TYPE for more information.\n", "\n\n\n\n8.17.2.\u00a0Examples #\n\n\n\nCREATE TABLE reservation (room int, during tsrange);\nINSERT INTO reservation VALUES\n    (1108, '[2010-01-01 14:30, 2010-01-01 15:30)');\n\n-- Containment\nSELECT int4range(10, 20) @> 3;\n\n-- Overlaps\nSELECT numrange(11.1, 22.2) && numrange(20.0, 30.0);\n\n-- Extract the upper bound\nSELECT upper(int8range(15, 25));\n\n-- Compute the intersection\nSELECT int4range(10, 20) * int4range(15, 25);\n\n-- Is the range empty?\nSELECT isempty(numrange(1, 5));\n\nSee Table\u00a09.55 and Table\u00a09.57 for complete lists of operators and functions on range types.\n", "\n\n\n\n8.17.3.\u00a0Inclusive and Exclusive Bounds #\n\n\n\nEvery non-empty range has two bounds, the lower bound and the upper bound. All points between these values are included in the range. An inclusive bound means that the boundary point itself is included in the range as well, while an exclusive bound means that the boundary point is not included in the range.\nIn the text form of a range, an inclusive lower bound is represented by \u201c[\u201d while an exclusive lower bound is represented by \u201c(\u201d. Likewise, an inclusive upper bound is represented by \u201c]\u201d, while an exclusive upper bound is represented by \u201c)\u201d. (See Section\u00a08.17.5 for more details.)\nThe functions lower_inc and upper_inc test the inclusivity of the lower and upper bounds of a range value, respectively.\n", "\n\n\n\n8.17.4.\u00a0Infinite (Unbounded) Ranges #\n\n\n\nThe lower bound of a range can be omitted, meaning that all values less than the upper bound are included in the range, e.g., (,3]. Likewise, if the upper bound of the range is omitted, then all values greater than the lower bound are included in the range. If both lower and upper bounds are omitted, all values of the element type are considered to be in the range. Specifying a missing bound as inclusive is automatically converted to exclusive, e.g., [,] is converted to (,). You can think of these missing values as +/-infinity, but they are special range type values and are considered to be beyond any range element type's +/-infinity values.\nElement types that have the notion of \u201cinfinity\u201d can use them as explicit bound values. For example, with timestamp ranges, [today,infinity) excludes the special timestamp value infinity, while [today,infinity] include it, as does [today,) and [today,].\nThe functions lower_inf and upper_inf test for infinite lower and upper bounds of a range, respectively.\n", "\n\n\n\n8.17.5.\u00a0Range Input/Output #\n\n\n\nThe input for a range value must follow one of the following patterns:\n(lower-bound,upper-bound)\n(lower-bound,upper-bound]\n[lower-bound,upper-bound)\n[lower-bound,upper-bound]\nempty\n\nThe parentheses or brackets indicate whether the lower and upper bounds are exclusive or inclusive, as described previously. Notice that the final pattern is empty, which represents an empty range (a range that contains no points).\nThe lower-bound may be either a string that is valid input for the subtype, or empty to indicate no lower bound. Likewise, upper-bound may be either a string that is valid input for the subtype, or empty to indicate no upper bound.\nEach bound value can be quoted using \" (double quote) characters. This is necessary if the bound value contains parentheses, brackets, commas, double quotes, or backslashes, since these characters would otherwise be taken as part of the range syntax. To put a double quote or backslash in a quoted bound value, precede it with a backslash. (Also, a pair of double quotes within a double-quoted bound value is taken to represent a double quote character, analogously to the rules for single quotes in SQL literal strings.) Alternatively, you can avoid quoting and use backslash-escaping to protect all data characters that would otherwise be taken as range syntax. Also, to write a bound value that is an empty string, write \"\", since writing nothing means an infinite bound.\nWhitespace is allowed before and after the range value, but any whitespace between the parentheses or brackets is taken as part of the lower or upper bound value. (Depending on the element type, it might or might not be significant.)\n\nNote\nThese rules are very similar to those for writing field values in composite-type literals. See Section\u00a08.16.6 for additional commentary.\n\nExamples:\n-- includes 3, does not include 7, and does include all points in between\nSELECT '[3,7)'::int4range;\n\n-- does not include either 3 or 7, but includes all points in between\nSELECT '(3,7)'::int4range;\n\n-- includes only the single point 4\nSELECT '[4,4]'::int4range;\n\n-- includes no points (and will be normalized to 'empty')\nSELECT '[4,4)'::int4range;\n\nThe input for a multirange is curly brackets ({ and }) containing zero or more valid ranges, separated by commas. Whitespace is permitted around the brackets and commas. This is intended to be reminiscent of array syntax, although multiranges are much simpler: they have just one dimension and there is no need to quote their contents. (The bounds of their ranges may be quoted as above however.)\nExamples:\nSELECT '{}'::int4multirange;\nSELECT '{[3,7)}'::int4multirange;\nSELECT '{[3,7), [8,9)}'::int4multirange;\n\n", "\n\n\n\n8.17.6.\u00a0Constructing Ranges and Multiranges #\n\n\n\nEach range type has a constructor function with the same name as the range type. Using the constructor function is frequently more convenient than writing a range literal constant, since it avoids the need for extra quoting of the bound values. The constructor function accepts two or three arguments. The two-argument form constructs a range in standard form (lower bound inclusive, upper bound exclusive), while the three-argument form constructs a range with bounds of the form specified by the third argument. The third argument must be one of the strings \u201c()\u201d, \u201c(]\u201d, \u201c[)\u201d, or \u201c[]\u201d. For example:\n-- The full form is: lower bound, upper bound, and text argument indicating\n-- inclusivity/exclusivity of bounds.\nSELECT numrange(1.0, 14.0, '(]');\n\n-- If the third argument is omitted, '[)' is assumed.\nSELECT numrange(1.0, 14.0);\n\n-- Although '(]' is specified here, on display the value will be converted to\n-- canonical form, since int8range is a discrete range type (see below).\nSELECT int8range(1, 14, '(]');\n\n-- Using NULL for either bound causes the range to be unbounded on that side.\nSELECT numrange(NULL, 2.2);\n\nEach range type also has a multirange constructor with the same name as the multirange type. The constructor function takes zero or more arguments which are all ranges of the appropriate type. For example:\nSELECT nummultirange();\nSELECT nummultirange(numrange(1.0, 14.0));\nSELECT nummultirange(numrange(1.0, 14.0), numrange(20.0, 25.0));\n\n", "\n\n\n\n8.17.7.\u00a0Discrete Range Types #\n\n\n\nA discrete range is one whose element type has a well-defined \u201cstep\u201d, such as integer or date. In these types two elements can be said to be adjacent, when there are no valid values between them. This contrasts with continuous ranges, where it's always (or almost always) possible to identify other element values between two given values. For example, a range over the numeric type is continuous, as is a range over timestamp. (Even though timestamp has limited precision, and so could theoretically be treated as discrete, it's better to consider it continuous since the step size is normally not of interest.)\nAnother way to think about a discrete range type is that there is a clear idea of a \u201cnext\u201d or \u201cprevious\u201d value for each element value. Knowing that, it is possible to convert between inclusive and exclusive representations of a range's bounds, by choosing the next or previous element value instead of the one originally given. For example, in an integer range type [4,8] and (3,9) denote the same set of values; but this would not be so for a range over numeric.\nA discrete range type should have a canonicalization function that is aware of the desired step size for the element type. The canonicalization function is charged with converting equivalent values of the range type to have identical representations, in particular consistently inclusive or exclusive bounds. If a canonicalization function is not specified, then ranges with different formatting will always be treated as unequal, even though they might represent the same set of values in reality.\nThe built-in range types int4range, int8range, and daterange all use a canonical form that includes the lower bound and excludes the upper bound; that is, [). User-defined range types can use other conventions, however.\n", "\n\n\n\n8.17.8.\u00a0Defining New Range Types #\n\n\n\nUsers can define their own range types. The most common reason to do this is to use ranges over subtypes not provided among the built-in range types. For example, to define a new range type of subtype float8:\nCREATE TYPE floatrange AS RANGE (\n    subtype = float8,\n    subtype_diff = float8mi\n);\n\nSELECT '[1.234, 5.678]'::floatrange;\n\nBecause float8 has no meaningful \u201cstep\u201d, we do not define a canonicalization function in this example.\nWhen you define your own range you automatically get a corresponding multirange type.\nDefining your own range type also allows you to specify a different subtype B-tree operator class or collation to use, so as to change the sort ordering that determines which values fall into a given range.\nIf the subtype is considered to have discrete rather than continuous values, the CREATE TYPE command should specify a canonical function. The canonicalization function takes an input range value, and must return an equivalent range value that may have different bounds and formatting. The canonical output for two ranges that represent the same set of values, for example the integer ranges [1, 7] and [1, 8), must be identical. It doesn't matter which representation you choose to be the canonical one, so long as two equivalent values with different formattings are always mapped to the same value with the same formatting. In addition to adjusting the inclusive/exclusive bounds format, a canonicalization function might round off boundary values, in case the desired step size is larger than what the subtype is capable of storing. For instance, a range type over timestamp could be defined to have a step size of an hour, in which case the canonicalization function would need to round off bounds that weren't a multiple of an hour, or perhaps throw an error instead.\nIn addition, any range type that is meant to be used with GiST or SP-GiST indexes should define a subtype difference, or subtype_diff, function. (The index will still work without subtype_diff, but it is likely to be considerably less efficient than if a difference function is provided.) The subtype difference function takes two input values of the subtype, and returns their difference (i.e., X minus Y) represented as a float8 value. In our example above, the function float8mi that underlies the regular float8 minus operator can be used; but for any other subtype, some type conversion would be necessary. Some creative thought about how to represent differences as numbers might be needed, too. To the greatest extent possible, the subtype_diff function should agree with the sort ordering implied by the selected operator class and collation; that is, its result should be positive whenever its first argument is greater than its second according to the sort ordering.\nA less-oversimplified example of a subtype_diff function is:\nCREATE FUNCTION time_subtype_diff(x time, y time) RETURNS float8 AS\n'SELECT EXTRACT(EPOCH FROM (x - y))' LANGUAGE sql STRICT IMMUTABLE;\n\nCREATE TYPE timerange AS RANGE (\n    subtype = time,\n    subtype_diff = time_subtype_diff\n);\n\nSELECT '[11:10, 23:00]'::timerange;\n\nSee CREATE TYPE for more information about creating range types.\n", "\n\n\n\n8.17.9.\u00a0Indexing #\n\n\n\nGiST and SP-GiST indexes can be created for table columns of range types. GiST indexes can be also created for table columns of multirange types. For instance, to create a GiST index:\nCREATE INDEX reservation_idx ON reservation USING GIST (during);\n\nA GiST or SP-GiST index on ranges can accelerate queries involving these range operators: =, &&, <@, @>, <<, >>, -|-, &<, and &>. A GiST index on multiranges can accelerate queries involving the same set of multirange operators. A GiST index on ranges and GiST index on multiranges can also accelerate queries involving these cross-type range to multirange and multirange to range operators correspondingly: &&, <@, @>, <<, >>, -|-, &<, and &>. See Table\u00a09.55 for more information.\nIn addition, B-tree and hash indexes can be created for table columns of range types. For these index types, basically the only useful range operation is equality. There is a B-tree sort ordering defined for range values, with corresponding < and > operators, but the ordering is rather arbitrary and not usually useful in the real world. Range types' B-tree and hash support is primarily meant to allow sorting and hashing internally in queries, rather than creation of actual indexes.\n", "\n\n\n\n8.17.10.\u00a0Constraints on Ranges #\n\n\n\nWhile UNIQUE is a natural constraint for scalar values, it is usually unsuitable for range types. Instead, an exclusion constraint is often more appropriate (see CREATE TABLE ... CONSTRAINT ... EXCLUDE). Exclusion constraints allow the specification of constraints such as \u201cnon-overlapping\u201d on a range type. For example:\nCREATE TABLE reservation (\n    during tsrange,\n    EXCLUDE USING GIST (during WITH &&)\n);\n\nThat constraint will prevent any overlapping values from existing in the table at the same time:\nINSERT INTO reservation VALUES\n    ('[2010-01-01 11:30, 2010-01-01 15:00)');\nINSERT 0 1\n\nINSERT INTO reservation VALUES\n    ('[2010-01-01 14:45, 2010-01-01 15:45)');\nERROR:  conflicting key value violates exclusion constraint \"reservation_during_excl\"\nDETAIL:  Key (during)=([\"2010-01-01 14:45:00\",\"2010-01-01 15:45:00\")) conflicts\nwith existing key (during)=([\"2010-01-01 11:30:00\",\"2010-01-01 15:00:00\")).\n\nYou can use the btree_gist extension to define exclusion constraints on plain scalar data types, which can then be combined with range exclusions for maximum flexibility. For example, after btree_gist is installed, the following constraint will reject overlapping ranges only if the meeting room numbers are equal:\nCREATE EXTENSION btree_gist;\nCREATE TABLE room_reservation (\n    room text,\n    during tsrange,\n    EXCLUDE USING GIST (room WITH =, during WITH &&)\n);\n\nINSERT INTO room_reservation VALUES\n    ('123A', '[2010-01-01 14:00, 2010-01-01 15:00)');\nINSERT 0 1\n\nINSERT INTO room_reservation VALUES\n    ('123A', '[2010-01-01 14:30, 2010-01-01 15:30)');\nERROR:  conflicting key value violates exclusion constraint \"room_reservation_room_during_excl\"\nDETAIL:  Key (room, during)=(123A, [\"2010-01-01 14:30:00\",\"2010-01-01 15:30:00\")) conflicts\nwith existing key (room, during)=(123A, [\"2010-01-01 14:00:00\",\"2010-01-01 15:00:00\")).\n\nINSERT INTO room_reservation VALUES\n    ('123B', '[2010-01-01 14:30, 2010-01-01 15:30)');\nINSERT 0 1\n\n"], "Examples": [], "Category": ["Nested or Composite Data Types"]}
